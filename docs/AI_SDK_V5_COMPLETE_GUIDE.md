# Guia Completo de ConfiguraÃ§Ã£o do Vercel AI SDK v5 para Zenith Tasks

## ğŸ“š Ãndice
1. [IntroduÃ§Ã£o e VisÃ£o Geral](#introduÃ§Ã£o)
2. [Arquitetura e Estrutura](#arquitetura)
3. [ConfiguraÃ§Ã£o de Modelos](#configuraÃ§Ã£o-de-modelos)
4. [ImplementaÃ§Ã£o de Tools e Tool Calling](#tools-e-tool-calling)
5. [MCP (Model Context Protocol)](#mcp-integration)
6. [Streaming e Eventos](#streaming-e-eventos)
7. [Structured Output com Zod](#structured-output)
8. [Melhores PrÃ¡ticas e PadrÃµes](#melhores-prÃ¡ticas)
9. [Exemplos de ImplementaÃ§Ã£o](#exemplos-completos)
10. [Tratamento de Erros e SeguranÃ§a](#erros-e-seguranÃ§a)

---

## 1. IntroduÃ§Ã£o e VisÃ£o Geral {#introduÃ§Ã£o}

### O que Ã© o AI SDK v5?

O Vercel AI SDK v5 Ã© o primeiro framework de IA com integraÃ§Ã£o de chat totalmente tipada e altamente personalizÃ¡vel para React, Svelte, Vue e Angular. LanÃ§ado em 2025, representa uma evoluÃ§Ã£o significativa com:

- **Type-safety completo** com TypeScript
- **Suporte nativo para MCP** (Model Context Protocol)
- **Streaming otimizado** com Server-Sent Events (SSE)
- **Ferramentas dinÃ¢micas** e estÃ¡ticas
- **Controle granular** sobre agentes e fluxos

### Principais MudanÃ§as do v4 para v5

```typescript
// v4 (antigo)
const { messages, append } = useChat({
  toolCallStreaming: true, // opcional
});

// v5 (novo)
const { messages, sendMessage } = useChat({
  // toolCallStreaming sempre ativo por padrÃ£o
});
```

### Feedback da Comunidade (2024-2025)

- "A Ãºnica abstraÃ§Ã£o perfeita que vi atÃ© agora"
- "API muito mais limpa e intuitiva"
- "ConstruÃ­do por pessoas obcecadas com TypeScript"
- Redis recomendado para persistÃªncia em produÃ§Ã£o
---

##
 2. Arquitetura e Estrutura {#arquitetura}

### Estrutura Recomendada do Projeto

```
zenith-tasks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ assistant/
â”‚   â”‚       â”‚   â”œâ”€â”€ route.ts          # Endpoint principal do assistente
â”‚   â”‚       â”‚   â”œâ”€â”€ chat/route.ts     # Chat streaming
â”‚   â”‚       â”‚   â””â”€â”€ act/route.ts      # ExecuÃ§Ã£o de ferramentas
â”‚   â”‚       â””â”€â”€ mcp/
â”‚   â”‚           â””â”€â”€ servers/
â”‚   â”‚               â””â”€â”€ [id]/
â”‚   â”‚                   â”œâ”€â”€ route.ts
â”‚   â”‚                   â”œâ”€â”€ tools/route.ts
â”‚   â”‚                   â””â”€â”€ call/route.ts
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â”œâ”€â”€ aiProvider.ts             # ConfiguraÃ§Ã£o de modelos
â”‚   â”‚   â”œâ”€â”€ mcpRegistry.ts            # Registro de servidores MCP
â”‚   â”‚   â””â”€â”€ tools/                    # DefiniÃ§Ãµes de ferramentas
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ ai/
â”‚           â”œâ”€â”€ assistant.ts          # LÃ³gica do assistente
â”‚           â”œâ”€â”€ tools.ts              # ImplementaÃ§Ã£o de ferramentas
â”‚           â””â”€â”€ schemas.ts            # Schemas Zod
```

### ConfiguraÃ§Ã£o do Provider Melhorada

```typescript
// src/server/aiProvider.ts
import { LanguageModel } from 'ai';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { createOpenAI } from '@ai-sdk/openai';
import { createAnthropic } from '@ai-sdk/anthropic';

export interface AIProviderConfig {
  provider: 'google' | 'openrouter' | 'anthropic' | 'openai';
  model?: string;
  apiKey?: string;
  baseURL?: string;
  structuredOutputs?: boolean;
  temperature?: number;
  maxTokens?: number;
}

export class AIProvider {
  private static instance: AIProvider;
  private models: Map<string, LanguageModel> = new Map();

  static getInstance(): AIProvider {
    if (!this.instance) {
      this.instance = new AIProvider();
    }
    return this.instance;
  }

  async getModel(config?: Partial<AIProviderConfig>): Promise<LanguageModel> {
    const provider = config?.provider || process.env.AI_SDK_PROVIDER || 'google';
    const cacheKey = `${provider}-${config?.model || 'default'}`;

    if (this.models.has(cacheKey)) {
      return this.models.get(cacheKey)!;
    }

    const model = await this.createModel(provider, config);
    this.models.set(cacheKey, model);
    return model;
  }

  private async createModel(
    provider: string,
    config?: Partial<AIProviderConfig>
  ): Promise<LanguageModel> {
    switch (provider.toLowerCase()) {
      case 'google': {
        const apiKey = config?.apiKey || process.env.GEMINI_API_KEY;
        if (!apiKey) throw new Error('GEMINI_API_KEY missing');

        const google = createGoogleGenerativeAI({
          apiKey,
          // ConfiguraÃ§Ãµes especÃ­ficas do Google
          providerOptions: {
            google: {
              structuredOutputs: config?.structuredOutputs ?? true,
            }
          }
        });

        const modelName = config?.model || process.env.GEMINI_MODEL || 'gemini-2.5-pro';
        return google(modelName);
      }

      case 'openrouter': {
        const apiKey = config?.apiKey || process.env.OPENROUTER_API_KEY;
        if (!apiKey) throw new Error('OPENROUTER_API_KEY missing');

        const openai = createOpenAI({
          apiKey,
          baseURL: config?.baseURL || 'https://openrouter.ai/api/v1',
          // Headers customizados para OpenRouter
          headers: {
            'X-Title': 'Zenith Tasks AI Assistant',
            'HTTP-Referer': process.env.NEXT_PUBLIC_URL || 'http://localhost:3457'
          }
        });

        const modelName = config?.model || process.env.OPENROUTER_MODEL || 'openrouter/auto';
        return openai(modelName);
      }

      case 'anthropic': {
        const apiKey = config?.apiKey || process.env.ANTHROPIC_API_KEY;
        if (!apiKey) throw new Error('ANTHROPIC_API_KEY missing');

        const anthropic = createAnthropic({ apiKey });
        const modelName = config?.model || 'claude-3-5-sonnet-20241022';
        return anthropic(modelName);
      }

      case 'openai': {
        const apiKey = config?.apiKey || process.env.OPENAI_API_KEY;
        if (!apiKey) throw new Error('OPENAI_API_KEY missing');

        const openai = createOpenAI({ apiKey });
        const modelName = config?.model || 'gpt-4o';
        return openai(modelName);
      }

      default:
        throw new Error(`Provider ${provider} not supported`);
    }
  }
}

// Helper function para compatibilidade com cÃ³digo existente
export async function getAISDKModel(config?: Partial<AIProviderConfig>) {
  return AIProvider.getInstance().getModel(config);
}
```