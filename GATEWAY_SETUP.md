# Como Usar AI Gateway ao Inv√©s do OpenRouter

O projeto **j√° possui implementa√ß√£o completa do AI Gateway** (Portkey/Vercel AI Gateway) que √© mais confi√°vel que o OpenRouter com AI SDK v5.

## ‚úÖ Vantagens do AI Gateway

1. **Compatibilidade Total** com AI SDK v5
2. **Fallback Autom√°tico** entre provedores
3. **Cache e Rate Limiting** integrados
4. **Sele√ß√£o Inteligente** de modelos baseada em contexto
5. **Gerenciamento de Cr√©ditos** centralizado

## üîß Configura√ß√£o

### 1. Adicionar Vari√°veis de Ambiente

No seu arquivo `.env.local`, adicione:

```bash
# AI Gateway Configuration
AI_GATEWAY_API_KEY=sua_chave_aqui
USE_AI_GATEWAY=true

# Opcional: URL customizada (padr√£o: https://api.portkey.ai/v1)
AI_GATEWAY_BASE_URL=https://api.portkey.ai/v1
```

### 2. Obter API Key

O projeto suporta dois gateways:

**Op√ß√£o 1: Portkey (Recomendado)**
- Acesse: https://portkey.ai
- Crie uma conta gratuita
- Obtenha sua API key em Settings > API Keys
- Configure seus provedores (OpenAI, Anthropic, Google, etc.)

**Op√ß√£o 2: Vercel AI Gateway**
- Se voc√™ usar deploy na Vercel, o gateway j√° est√° dispon√≠vel
- Configure em: https://vercel.com/dashboard/ai

### 3. Remover/Comentar OpenRouter (opcional)

No `.env.local`, voc√™ pode remover ou comentar:

```bash
# AI_SDK_PROVIDER=openrouter  # <-- comentar esta linha
# OPENROUTER_API_KEY=...       # <-- comentar esta linha
```

## üöÄ Como Funciona

### Fluxo Autom√°tico

Quando voc√™ configura o Gateway, o sistema automaticamente:

1. **Tenta usar o Gateway primeiro** se `USE_AI_GATEWAY=true`
2. **Seleciona o melhor modelo** baseado no contexto da tarefa:
   - `analysis` ‚Üí Modelos determin√≠sticos (temp=0.3)
   - `creative` ‚Üí Modelos criativos (temp=0.9)
   - `code` ‚Üí Modelos para c√≥digo (temp=0.2)
   - `chat` ‚Üí Modelos balanceados (temp=0.7)
3. **Faz fallback** para provedores diretos se o Gateway falhar
4. **Gerencia cr√©ditos** automaticamente

### Sele√ß√£o de Modelos

O Gateway escolhe modelos automaticamente baseado em:

```typescript
// Contextos dispon√≠veis
'task-planning'    // Planejamento de tarefas
'creative-writing' // Escrita criativa
'code-generation'  // Gera√ß√£o de c√≥digo
'chat'             // Chat geral
'analysis'         // An√°lise de dados
```

## üìä Verificar Status

### Via API Debug

```bash
curl http://localhost:3457/api/debug/providers
```

Retorna:

```json
{
  "gateway": {
    "configured": true,
    "enabled": true,
    "key": "pk-xxxxx..."
  },
  "providers": {
    "zai": { "configured": true },
    "google": { "configured": false },
    "openrouter": { "configured": true }
  },
  "recommendations": [
    "Gateway est√° ativo e funcionando"
  ]
}
```

### Via Logs

Quando o servidor iniciar, voc√™ ver√°:

```
[AIProvider] Attempting to use AI Gateway
[Gateway] Initialized with API key
[Gateway] Loaded real models from API
[AIProvider] Using Gateway model: openai/gpt-4o
```

## üîÑ Migra√ß√£o do OpenRouter para Gateway

### Antes (com erros AI SDK v5):

```bash
AI_SDK_PROVIDER=openrouter
OPENROUTER_API_KEY=sk-or-...
OPENROUTER_MODEL=google/gemma-2-9b-it:free
```

### Depois (est√°vel):

```bash
# Ativar Gateway
USE_AI_GATEWAY=true
AI_GATEWAY_API_KEY=pk-portkey-...

# Gateway vai usar o modelo mais adequado automaticamente
# Ou voc√™ pode especificar: AI_GATEWAY_DEFAULT_MODEL=openai/gpt-4o
```

## üõ†Ô∏è Configura√ß√£o Avan√ßada

### Fallback Providers

O Gateway pode fazer fallback entre m√∫ltiplos provedores:

```typescript
// No c√≥digo (j√° implementado)
const gateway = new GatewayProvider({
  apiKey: process.env.AI_GATEWAY_API_KEY,
  fallbackProviders: ['openai', 'anthropic', 'google']
});
```

### Cache de Modelos

```typescript
// Cache autom√°tico de 5 minutos (configur√°vel)
const gateway = new GatewayProvider({
  metadataCacheRefreshMillis: 5 * 60 * 1000
});
```

## üêõ Troubleshooting

### Gateway n√£o est√° sendo usado

1. Verifique se `USE_AI_GATEWAY=true` est√° definido
2. Verifique se `AI_GATEWAY_API_KEY` est√° presente
3. Veja os logs do servidor para mensagens do Gateway

### Erro "Gateway not available"

- Verifique sua API key em https://portkey.ai
- Teste a conex√£o: `curl -H "x-portkey-api-key: $AI_GATEWAY_API_KEY" https://api.portkey.ai/v1/models`

### Ainda usando OpenRouter

- Confirme que `.env.local` tem as vari√°veis corretas
- Reinicie o servidor: `npm run dev`
- Limpe o cache: `rm -rf .next && npm run dev`

## üìö Arquivos Relacionados

- `src/server/ai/gateway/provider.ts` - Implementa√ß√£o do Gateway
- `src/server/aiProvider.ts` - Gerenciador de AI providers
- `src/app/api/debug/providers/route.ts` - Debug endpoint
- `test-ai-gateway.ts` - Script de teste do Gateway

## üéØ Pr√≥ximos Passos

1. Obtenha sua chave do Portkey
2. Configure as vari√°veis de ambiente
3. Reinicie o servidor
4. Teste com: `/api/inbox/analyze` ou chat assistant
5. Monitore os logs para confirmar uso do Gateway

---

**Nota**: O Gateway resolve todos os problemas de compatibilidade com AI SDK v5 que voc√™ est√° enfrentando com OpenRouter!
